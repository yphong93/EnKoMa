# EnKoMa Model Comparison Framework

A comprehensive framework for comparing EnKoMa (Enhanced Koopman via Mamba) model with baseline models on synthetic and real-world time series datasets.

## ğŸ“ Directory Structure

```
model_20260124/
â”œâ”€â”€ models/                    # Model implementations
â”‚   â”œâ”€â”€ enkoma.py             # EnKoMa model
â”‚   â”œâ”€â”€ deep_koopman.py       # Deep Koopman baseline
â”‚   â”œâ”€â”€ pure_mamba.py         # Pure Mamba model
â”‚   â”œâ”€â”€ lstm.py               # LSTM model
â”‚   â”œâ”€â”€ transformer.py       # Transformer model
â”‚   â”œâ”€â”€ gru.py                # GRU model
â”‚   â”œâ”€â”€ linear.py             # Linear baseline
â”‚   â””â”€â”€ components.py         # Shared components
â”œâ”€â”€ system/                    # System implementations
â”‚   â”œâ”€â”€ synthetic.py          # Synthetic systems (Lorenz, Van der Pol, Duffing, etc.)
â”‚   â””â”€â”€ real_data.py          # Real data loaders (ETT, SST, AirQuality, NASA Bearing, EnergyConsumption)
â”œâ”€â”€ configs/                   # Configuration files
â”‚   â”œâ”€â”€ config_Lorenz.json
â”‚   â”œâ”€â”€ config_SST_improved.json
â”‚   â”œâ”€â”€ config_AirQuality.json
â”‚   â””â”€â”€ ...                   # Other config files
â”œâ”€â”€ analysis/                  # Analysis tools
â”‚   â”œâ”€â”€ visualization.py      # Plotting functions
â”‚   â”œâ”€â”€ eigenvalue.py         # Eigenvalue analysis
â”‚   â””â”€â”€ robustness.py         # Robustness testing
â”œâ”€â”€ utils/                     # Utility functions
â”‚   â”œâ”€â”€ metrics.py            # Evaluation metrics
â”‚   â””â”€â”€ lyapunov.py           # Lyapunov time calculation
â”œâ”€â”€ data/                      # Data directory
â”‚   â””â”€â”€ real_data/            # Real-world datasets
â”œâ”€â”€ compare_experiment.py      # Main comparison experiment script
â”œâ”€â”€ ablation_test_loss.py      # Ablation test script
â”œâ”€â”€ config.py                  # Configuration class
â””â”€â”€ compare_result/            # Experiment results directory
```

## ğŸš€ Quick Start

### 1. Comparison Experiment

Run comparison experiments with multiple models:

```bash
# Synthetic systems
python compare_experiment.py configs/config_Lorenz.json

# Real-world datasets
python compare_experiment.py configs/config_AirQuality.json
```

### 2. Ablation Test

Test different loss component combinations:

```bash
python ablation_test_loss.py --config configs/config_AirQuality.json
```

## ğŸ“Š Supported Datasets

### Synthetic Systems
- **Lorenz System**: Chaotic system
- **Van der Pol Oscillator**: Nonlinear oscillator
- **Duffing Oscillator**: Forced oscillation system
- **Burgers Equation**: Fluid dynamics
- **Kuramoto-Sivashinsky**: Spatiotemporal chaos

### Real-World Datasets
- **ETT**: Electricity Transformer Temperature (ETTh1, ETTh2, ETTm1, ETTm2)
- **SST**: NOAA Sea Surface Temperature
- **AirQuality**: Air quality monitoring data
- **NASA Bearing**: Bearing degradation dataset
- **EnergyConsumption**: Energy consumption dataset

## ğŸ”§ Configuration Files

Configuration files are located in `configs/` directory. Each config file specifies:
- Model hyperparameters (latent_dim, seq_len, pred_len, etc.)
- Training settings (epochs, lr, batch_size, etc.)
- Loss weights (alpha_rec, alpha_pred, alpha_spectral, etc.)
- Data preprocessing options (detrend_method, normalization_method, etc.)

## ğŸ“ˆ Evaluation Metrics

The framework evaluates models using:
- **MSE** (Mean Squared Error)
- **RMSE** (Root Mean Squared Error)
- **MAE** (Mean Absolute Error)
- **MAPE** (Mean Absolute Percentage Error)
- **RÂ² Score** (Coefficient of Determination)

Metrics are computed for:
- **Short-term prediction**: Configurable steps (e.g., 6, 12, 18)
- **Long-term prediction**: Configurable steps (e.g., 36, 48, 60)

## ğŸ“ Results Structure

Results are saved in `compare_result/{system_name}/{system_name}_{timestamp}/`:

```
compare_result/SST_SST/SST_SST_20260127_160817/
â”œâ”€â”€ config.json                    # Used configuration
â”œâ”€â”€ experiment.log                  # Full experiment log
â”œâ”€â”€ results_summary.json           # Results summary (JSON)
â”œâ”€â”€ metrics_summary.csv           # Overall metrics (CSV)
â”œâ”€â”€ stepwise_metrics.csv          # Step-wise metrics (CSV)
â”œâ”€â”€ metrics_comparison.png        # Metrics comparison chart
â”œâ”€â”€ stepwise_*.png                # Step-wise comparison charts
â””â”€â”€ {model_name}/                 # Per-model results
    â”œâ”€â”€ pred_vs_gt_sample_0.png
    â”œâ”€â”€ phase_space_*.png
    â”œâ”€â”€ {model_name}_predictions_sample_0.csv
    â””â”€â”€ eigenvalues/              # Eigenvalue analysis (EnKoMa only)
        â”œâ”€â”€ eigenvalue_analysis.png
        â””â”€â”€ global_jacobian_stitching.png
```

## ğŸ”¬ Analysis Features

### Phase Space Visualization
- 2D and 3D phase space reconstruction
- Trajectory comparison between models

### Eigenvalue Analysis (EnKoMa only)
- Global Jacobian stitching
- Complex plane distribution
- Mode frequency analysis
- Spectral radius tracking

### Robustness Testing
- Noise injection at various levels
- Performance degradation analysis

## ğŸ“ Data Preparation

### Real-World Data

Place your data files in `data/real_data/`:

- **ETT**: `ETTh1.csv`, `ETTh2.csv`, `ETTm1.csv`, `ETTm2.csv`
- **SST**: `sst.csv`
- **AirQuality**: `air_quality.csv`
- **NASA Bearing**: `bearing_1.csv`, `bearing_2.csv`, etc.
- **EnergyConsumption**: `Energy_consumption_dataset.csv`

### Data Preprocessing

The framework automatically applies:
- **Detrending**: Removes trends (linear, polynomial, or seasonal)
- **Normalization**: StandardScaler, RobustScaler, or MinMaxScaler
- **Outlier handling**: IQR method for outlier capping
- **Smoothing**: Optional Gaussian filtering for noisy data

## ğŸ› ï¸ Dependencies

- PyTorch
- NumPy
- SciPy
- scikit-learn
- Matplotlib
- pandas

## ğŸ“š Additional Documentation

- `ABLATION_TEST_README.md`: Ablation test usage guide
- `SST_PREPROCESSING_VERIFICATION.md`: SST preprocessing details
- `EIGENVALUE_ANALYSIS_GUIDE.md`: Eigenvalue analysis guide
- Various analysis markdown files for specific experiments

## ğŸ’¡ Tips

1. **GPU Selection**: Use `CUDA_VISIBLE_DEVICES` to specify GPU
2. **Config Customization**: Modify config files to adjust hyperparameters
3. **Result Analysis**: Check `experiment.log` for detailed training logs
4. **Model Comparison**: Review `metrics_summary.csv` for quick comparison

## ğŸ“§ Support

For issues or questions, refer to the analysis markdown files in the root directory or check the experiment logs.
